{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b74d7b1-8e59-47c0-84d7-c44fd124bf16",
   "metadata": {},
   "source": [
    "### Jexpresso single grid comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c234a-0eff-45b9-8c71-bbe06f9d8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.interpolate import interp1d\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class EKEAnalysis:\n",
    "    \"\"\"Analyze JExpresso outputs using Domain Mean Subtraction method\"\"\"\n",
    "    \n",
    "    def __init__(self, ref_file, pert_file, max_height=24000):\n",
    "        self.ref_file = ref_file\n",
    "        self.pert_file = pert_file\n",
    "        self.max_height = max_height\n",
    "\n",
    "    def extract_jexpresso_data(self):\n",
    "        ref_mesh = pv.read(self.ref_file)\n",
    "        pert_mesh = pv.read(self.pert_file)\n",
    "        \n",
    "        if ref_mesh.n_points != pert_mesh.n_points:\n",
    "            z_ref = ref_mesh.points[:, 1]\n",
    "            ref_sort_idx = np.argsort(z_ref)\n",
    "            z_ref_sorted = z_ref[ref_sort_idx]\n",
    "            rho_ref = ref_mesh.point_data['ρ'][ref_sort_idx]\n",
    "            rho_u_ref = ref_mesh.point_data['ρu'][ref_sort_idx]\n",
    "            rho_v_ref = ref_mesh.point_data['ρv'][ref_sort_idx]\n",
    "            \n",
    "            z_pert = pert_mesh.points[:, 1]\n",
    "            pert_sort_idx = np.argsort(z_pert)\n",
    "            z_pert_sorted = z_pert[pert_sort_idx]\n",
    "            rho_pert = pert_mesh.point_data['ρ'][pert_sort_idx]\n",
    "            rho_u_pert = pert_mesh.point_data['ρu'][pert_sort_idx]\n",
    "            rho_v_pert = pert_mesh.point_data['ρv'][pert_sort_idx]\n",
    "            \n",
    "            if len(z_ref_sorted) > len(z_pert_sorted):\n",
    "                z_common = z_ref_sorted\n",
    "                f_rho_pert = interp1d(z_pert_sorted, rho_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_u_pert = interp1d(z_pert_sorted, rho_u_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_v_pert = interp1d(z_pert_sorted, rho_v_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                \n",
    "                rho_total = rho_ref + f_rho_pert(z_common)\n",
    "                rho_u_total = rho_u_ref + f_rho_u_pert(z_common)\n",
    "                rho_v_total = rho_v_ref + f_rho_v_pert(z_common)\n",
    "            else:\n",
    "                z_common = z_pert_sorted\n",
    "                f_rho_ref = interp1d(z_ref_sorted, rho_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_u_ref = interp1d(z_ref_sorted, rho_u_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_v_ref = interp1d(z_ref_sorted, rho_v_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                \n",
    "                rho_total = f_rho_ref(z_common) + rho_pert\n",
    "                rho_u_total = f_rho_u_ref(z_common) + rho_u_pert\n",
    "                rho_v_total = f_rho_v_ref(z_common) + rho_v_pert\n",
    "        else:\n",
    "            z_common = ref_mesh.points[:, 1]\n",
    "            rho_total = ref_mesh.point_data['ρ'] + pert_mesh.point_data['ρ']\n",
    "            rho_u_total = ref_mesh.point_data['ρu'] + pert_mesh.point_data['ρu']\n",
    "            rho_v_total = ref_mesh.point_data['ρv'] + pert_mesh.point_data['ρv']\n",
    "        \n",
    "        valid_mask = np.abs(rho_total) > 1e-10\n",
    "        u_total = np.zeros_like(rho_u_total)\n",
    "        v_total = np.zeros_like(rho_v_total)\n",
    "        u_total[valid_mask] = rho_u_total[valid_mask] / rho_total[valid_mask]\n",
    "        v_total[valid_mask] = rho_v_total[valid_mask] / rho_total[valid_mask]\n",
    "        \n",
    "        height_tolerance = 100.0\n",
    "        heights_rounded = np.round(z_common / height_tolerance) * height_tolerance\n",
    "        unique_heights_rounded = np.unique(heights_rounded)\n",
    "        \n",
    "        eke_profile = []\n",
    "        height_profile = []\n",
    "        \n",
    "        for h_target in unique_heights_rounded:\n",
    "            height_mask = np.abs(heights_rounded - h_target) < (height_tolerance / 2)\n",
    "            if np.sum(height_mask) < 2:\n",
    "                continue\n",
    "                \n",
    "            u_total_level = u_total[height_mask]\n",
    "            v_total_level = v_total[height_mask]\n",
    "            rho_level = rho_total[height_mask]\n",
    "            z_level = z_common[height_mask]\n",
    "            \n",
    "            valid_level_mask = (rho_level > 1e-10) & np.isfinite(u_total_level) & np.isfinite(v_total_level)\n",
    "            if np.sum(valid_level_mask) < 2:\n",
    "                continue\n",
    "                \n",
    "            u_total_level = u_total_level[valid_level_mask]\n",
    "            v_total_level = v_total_level[valid_level_mask]\n",
    "            rho_level = rho_level[valid_level_mask]\n",
    "            z_level = z_level[valid_level_mask]\n",
    "            \n",
    "            u_mean_level = np.mean(u_total_level)\n",
    "            v_mean_level = np.mean(v_total_level)\n",
    "            u_pert = u_total_level - u_mean_level\n",
    "            v_pert = v_total_level - v_mean_level\n",
    "            eke = 0.5 * rho_level * (u_pert**2 + v_pert**2)\n",
    "            eke_mean = np.mean(eke)\n",
    "            \n",
    "            if eke_mean > 1000 or eke_mean < 0 or not np.isfinite(eke_mean):\n",
    "                continue\n",
    "                \n",
    "            eke_profile.append(eke_mean)\n",
    "            height_profile.append(np.mean(z_level))\n",
    "            \n",
    "        if len(eke_profile) == 0:\n",
    "            self.jex_data = pd.DataFrame({'Height (m)': [], 'EKE (J/m3)': []})\n",
    "            return\n",
    "        \n",
    "        df_raw = pd.DataFrame({\n",
    "            \"Height (m)\": height_profile,\n",
    "            \"EKE (J/m3)\": eke_profile\n",
    "        })\n",
    "        self.jex_data = df_raw[df_raw[\"Height (m)\"] <= self.max_height].drop_duplicates(subset=[\"Height (m)\"]).sort_values('Height (m)').reset_index(drop=True)\n",
    "\n",
    "    def get_mean_eke(self):\n",
    "        \"\"\"Return mean EKE value\"\"\"\n",
    "        if len(self.jex_data) == 0:\n",
    "            return np.nan\n",
    "        return np.nanmean(self.jex_data[\"EKE (J/m3)\"].values)\n",
    "\n",
    "\n",
    "def process_configuration(ref_file, pert_base_path, max_time_minutes=500):\n",
    "    \"\"\"Process configuration and stop at max_time_minutes (default 500)\"\"\"\n",
    "    \n",
    "    if not Path(ref_file).exists():\n",
    "        print(f\"Reference file not found: {ref_file}\")\n",
    "        return None\n",
    "    \n",
    "    time_data = {'jex': [], 'times': []}\n",
    "    \n",
    "    max_iterations = max_time_minutes // 10\n",
    "    existing_pert_files = [i for i in range(max_iterations) if Path(pert_base_path.format(i)).exists()]\n",
    "    \n",
    "    if not existing_pert_files:\n",
    "        print(f\"No perturbation files found at: {pert_base_path}\")\n",
    "        return None\n",
    "    \n",
    "    successful_iterations = 0\n",
    "    for i in existing_pert_files:\n",
    "        try:\n",
    "            analysis = EKEAnalysis(ref_file, pert_base_path.format(i), max_height=24000)\n",
    "            analysis.extract_jexpresso_data()\n",
    "            \n",
    "            jex_total_eke = analysis.get_mean_eke()\n",
    "            \n",
    "            if np.isnan(jex_total_eke) or jex_total_eke > 500 or jex_total_eke < 0:\n",
    "                continue\n",
    "            \n",
    "            time_data['jex'].append(jex_total_eke)\n",
    "            time_data['times'].append(i * 10)\n",
    "            successful_iterations += 1\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully processed {successful_iterations} time steps\")\n",
    "    return time_data if len(time_data['jex']) > 0 else None\n",
    "\n",
    "\n",
    "def plot_fine_grid_sam(time_data, output_dir):\n",
    "    \"\"\"Create publication-quality plot for fine grid SAM only\"\"\"\n",
    "    \n",
    "    # Set publication-quality matplotlib parameters\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.linewidth'] = 1.5\n",
    "    plt.rcParams['xtick.major.width'] = 1.5\n",
    "    plt.rcParams['ytick.major.width'] = 1.5\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.set_facecolor('#FAFAFA')\n",
    "    \n",
    "    times = time_data['times']\n",
    "    jex_data = time_data['jex']\n",
    "    \n",
    "    # Determine y-axis limits\n",
    "    positive_values = [v for v in jex_data if v > 0]\n",
    "    if len(positive_values) > 0:\n",
    "        y_min = max(1e-7, min(positive_values) * 0.3)\n",
    "        y_max = max(positive_values) * 3.0\n",
    "    else:\n",
    "        y_min = 1e-7\n",
    "        y_max = 1e2\n",
    "    \n",
    "    # Replace zeros and negative values with y_min for log scale\n",
    "    jex_data_plot = [max(v, y_min) for v in jex_data]\n",
    "    \n",
    "    # Plot with distinctive styling\n",
    "    ax.semilogy(times, jex_data_plot,\n",
    "                color='#D97330',  # Dark orange\n",
    "                linestyle='-',     # Solid line\n",
    "                marker='o',        # Circle markers\n",
    "                markersize=8,\n",
    "                linewidth=2.5,\n",
    "                label='JExpresso EKE',\n",
    "                alpha=0.90,\n",
    "                markevery=max(1, len(times)//15),\n",
    "                markeredgewidth=1.5,\n",
    "                markeredgecolor='white',\n",
    "                zorder=4)\n",
    "    \n",
    "    # Set axis limits\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xlim(0, 500)\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel('Time (minutes)', fontsize=14, fontweight='600')\n",
    "    ax.set_ylabel('Mean EKE (J/m³)', fontsize=14, fontweight='600')\n",
    "    ax.set_title('Fine Grid (200m) - SAM Microphysics - Order 4\\nJExpresso EKE Analysis',\n",
    "                fontsize=16, fontweight='bold', pad=15)\n",
    "    \n",
    "    # Enhanced grid\n",
    "    ax.grid(True, alpha=0.15, color='gray', linewidth=0.5, linestyle=':', which='minor')\n",
    "    ax.grid(True, alpha=0.35, color='gray', linewidth=0.8, linestyle='-', which='major')\n",
    "    \n",
    "    # Enhanced spines\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('#333333')\n",
    "        spine.set_linewidth(1.5)\n",
    "    \n",
    "    # Improve tick appearance\n",
    "    ax.tick_params(axis='both', which='major', labelsize=11, width=1.5, length=7)\n",
    "    ax.tick_params(axis='both', which='minor', width=1.0, length=4)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(loc='best', fontsize=12, frameon=True, fancybox=True,\n",
    "             framealpha=0.95, edgecolor='#CCCCCC')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    filename = \"Fine_Grid_200m_SAM_Order4.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    plt.savefig(filepath, dpi=400, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "    plt.close()\n",
    "    print(f\"Saved plot: {filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Create output directory\n",
    "    output_base = \"/Users/olayemiadeyemi/Documents/sponge_on\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"Starting Fine Grid (200m) SAM Analysis - Order 4\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Define file paths\n",
    "    ref_file = \"/Users/olayemiadeyemi/Documents/New/reference_state/fine_4/output/iter_0.pvtu\"\n",
    "    pert_file = \"/Users/olayemiadeyemi/Documents/sponge_on/f_150_sam_4/output/iter_{}.pvtu\"\n",
    "    \n",
    "    print(f\"\\nReference file: {ref_file}\")\n",
    "    print(f\"Perturbation files: {pert_file}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Process the configuration\n",
    "    print(\"\\nProcessing fine grid SAM configuration...\")\n",
    "    try:\n",
    "        time_data = process_configuration(ref_file, pert_file, max_time_minutes=500)\n",
    "        \n",
    "        if time_data and len(time_data['jex']) > 0:\n",
    "            print(f\"✓ Successfully processed {len(time_data['jex'])} time steps\")\n",
    "            \n",
    "            # Generate plot\n",
    "            print(\"\\nGenerating publication-quality plot...\")\n",
    "            print(\"-\" * 80)\n",
    "            plot_fine_grid_sam(time_data, output_base)\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"Analysis complete!\")\n",
    "            print(f\"Output directory: {output_base}\")\n",
    "            print(\"=\" * 80)\n",
    "            print(f\"  - Plot saved: {output_base}/Fine_Grid_200m_SAM_Order4.png\")\n",
    "            print(\"=\" * 80)\n",
    "        else:\n",
    "            print(\"✗ No valid data found\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to process: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1f859-4be2-4c3f-85ca-196369d1f521",
   "metadata": {},
   "source": [
    "## Jexpresso multi-grid comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461df79-b260-44ce-b944-abe8abefa98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.interpolate import interp1d\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class EKEAnalysis:\n",
    "    \"\"\"Analyze JExpresso outputs using Domain Mean Subtraction method\"\"\"\n",
    "    \n",
    "    def __init__(self, ref_file, pert_file, max_height=24000):\n",
    "        self.ref_file = ref_file\n",
    "        self.pert_file = pert_file\n",
    "        self.max_height = max_height\n",
    "\n",
    "    def extract_jexpresso_data(self):\n",
    "        ref_mesh = pv.read(self.ref_file)\n",
    "        pert_mesh = pv.read(self.pert_file)\n",
    "        \n",
    "        if ref_mesh.n_points != pert_mesh.n_points:\n",
    "            z_ref = ref_mesh.points[:, 1]\n",
    "            ref_sort_idx = np.argsort(z_ref)\n",
    "            z_ref_sorted = z_ref[ref_sort_idx]\n",
    "            rho_ref = ref_mesh.point_data['ρ'][ref_sort_idx]\n",
    "            rho_u_ref = ref_mesh.point_data['ρu'][ref_sort_idx]\n",
    "            rho_v_ref = ref_mesh.point_data['ρv'][ref_sort_idx]\n",
    "            \n",
    "            z_pert = pert_mesh.points[:, 1]\n",
    "            pert_sort_idx = np.argsort(z_pert)\n",
    "            z_pert_sorted = z_pert[pert_sort_idx]\n",
    "            rho_pert = pert_mesh.point_data['ρ'][pert_sort_idx]\n",
    "            rho_u_pert = pert_mesh.point_data['ρu'][pert_sort_idx]\n",
    "            rho_v_pert = pert_mesh.point_data['ρv'][pert_sort_idx]\n",
    "            \n",
    "            if len(z_ref_sorted) > len(z_pert_sorted):\n",
    "                z_common = z_ref_sorted\n",
    "                f_rho_pert = interp1d(z_pert_sorted, rho_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_u_pert = interp1d(z_pert_sorted, rho_u_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_v_pert = interp1d(z_pert_sorted, rho_v_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                \n",
    "                rho_total = rho_ref + f_rho_pert(z_common)\n",
    "                rho_u_total = rho_u_ref + f_rho_u_pert(z_common)\n",
    "                rho_v_total = rho_v_ref + f_rho_v_pert(z_common)\n",
    "            else:\n",
    "                z_common = z_pert_sorted\n",
    "                f_rho_ref = interp1d(z_ref_sorted, rho_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_u_ref = interp1d(z_ref_sorted, rho_u_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_v_ref = interp1d(z_ref_sorted, rho_v_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                \n",
    "                rho_total = f_rho_ref(z_common) + rho_pert\n",
    "                rho_u_total = f_rho_u_ref(z_common) + rho_u_pert\n",
    "                rho_v_total = f_rho_v_ref(z_common) + rho_v_pert\n",
    "        else:\n",
    "            z_common = ref_mesh.points[:, 1]\n",
    "            rho_total = ref_mesh.point_data['ρ'] + pert_mesh.point_data['ρ']\n",
    "            rho_u_total = ref_mesh.point_data['ρu'] + pert_mesh.point_data['ρu']\n",
    "            rho_v_total = ref_mesh.point_data['ρv'] + pert_mesh.point_data['ρv']\n",
    "        \n",
    "        valid_mask = np.abs(rho_total) > 1e-10\n",
    "        u_total = np.zeros_like(rho_u_total)\n",
    "        v_total = np.zeros_like(rho_v_total)\n",
    "        u_total[valid_mask] = rho_u_total[valid_mask] / rho_total[valid_mask]\n",
    "        v_total[valid_mask] = rho_v_total[valid_mask] / rho_total[valid_mask]\n",
    "        \n",
    "        height_tolerance = 100.0\n",
    "        heights_rounded = np.round(z_common / height_tolerance) * height_tolerance\n",
    "        unique_heights_rounded = np.unique(heights_rounded)\n",
    "        \n",
    "        eke_profile = []\n",
    "        height_profile = []\n",
    "        \n",
    "        for h_target in unique_heights_rounded:\n",
    "            height_mask = np.abs(heights_rounded - h_target) < (height_tolerance / 2)\n",
    "            if np.sum(height_mask) < 2:\n",
    "                continue\n",
    "                \n",
    "            u_total_level = u_total[height_mask]\n",
    "            v_total_level = v_total[height_mask]\n",
    "            rho_level = rho_total[height_mask]\n",
    "            z_level = z_common[height_mask]\n",
    "            \n",
    "            valid_level_mask = (rho_level > 1e-10) & np.isfinite(u_total_level) & np.isfinite(v_total_level)\n",
    "            if np.sum(valid_level_mask) < 2:\n",
    "                continue\n",
    "                \n",
    "            u_total_level = u_total_level[valid_level_mask]\n",
    "            v_total_level = v_total_level[valid_level_mask]\n",
    "            rho_level = rho_level[valid_level_mask]\n",
    "            z_level = z_level[valid_level_mask]\n",
    "            \n",
    "            u_mean_level = np.mean(u_total_level)\n",
    "            v_mean_level = np.mean(v_total_level)\n",
    "            u_pert = u_total_level - u_mean_level\n",
    "            v_pert = v_total_level - v_mean_level\n",
    "            eke = 0.5 * rho_level * (u_pert**2 + v_pert**2)\n",
    "            eke_mean = np.mean(eke)\n",
    "            \n",
    "            if eke_mean > 1000 or eke_mean < 0 or not np.isfinite(eke_mean):\n",
    "                continue\n",
    "                \n",
    "            eke_profile.append(eke_mean)\n",
    "            height_profile.append(np.mean(z_level))\n",
    "            \n",
    "        if len(eke_profile) == 0:\n",
    "            self.jex_data = pd.DataFrame({'Height (m)': [], 'EKE (J/m3)': []})\n",
    "            return\n",
    "        \n",
    "        df_raw = pd.DataFrame({\n",
    "            \"Height (m)\": height_profile,\n",
    "            \"EKE (J/m3)\": eke_profile\n",
    "        })\n",
    "        self.jex_data = df_raw[df_raw[\"Height (m)\"] <= self.max_height].drop_duplicates(subset=[\"Height (m)\"]).sort_values('Height (m)').reset_index(drop=True)\n",
    "\n",
    "    def get_mean_eke(self):\n",
    "        \"\"\"Return mean EKE value\"\"\"\n",
    "        if len(self.jex_data) == 0:\n",
    "            return np.nan\n",
    "        return np.nanmean(self.jex_data[\"EKE (J/m3)\"].values)\n",
    "\n",
    "\n",
    "def process_configuration(ref_file, pert_base_path, max_time_minutes=500):\n",
    "    \"\"\"Process configuration and stop at max_time_minutes (default 500)\"\"\"\n",
    "    \n",
    "    if not Path(ref_file).exists():\n",
    "        print(f\"Reference file not found: {ref_file}\")\n",
    "        return None\n",
    "    \n",
    "    time_data = {'jex': [], 'times': []}\n",
    "    \n",
    "    max_iterations = max_time_minutes // 10\n",
    "    existing_pert_files = [i for i in range(max_iterations) if Path(pert_base_path.format(i)).exists()]\n",
    "    \n",
    "    if not existing_pert_files:\n",
    "        print(f\"No perturbation files found at: {pert_base_path}\")\n",
    "        return None\n",
    "    \n",
    "    successful_iterations = 0\n",
    "    for i in existing_pert_files:\n",
    "        try:\n",
    "            analysis = EKEAnalysis(ref_file, pert_base_path.format(i), max_height=24000)\n",
    "            analysis.extract_jexpresso_data()\n",
    "            \n",
    "            jex_total_eke = analysis.get_mean_eke()\n",
    "            \n",
    "            if np.isnan(jex_total_eke) or jex_total_eke > 500 or jex_total_eke < 0:\n",
    "                continue\n",
    "            \n",
    "            time_data['jex'].append(jex_total_eke)\n",
    "            time_data['times'].append(i * 10)\n",
    "            successful_iterations += 1\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully processed {successful_iterations} time steps\")\n",
    "    return time_data if len(time_data['jex']) > 0 else None\n",
    "\n",
    "\n",
    "def plot_comprehensive_grid(data_dict, output_dir):\n",
    "    \"\"\"Create publication-quality comprehensive 3x2 grid with color gradients\"\"\"\n",
    "    \n",
    "    # Set publication-quality matplotlib parameters\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    plt.rcParams['axes.linewidth'] = 1.2\n",
    "    plt.rcParams['xtick.major.width'] = 1.2\n",
    "    plt.rcParams['ytick.major.width'] = 1.2\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(20, 17))\n",
    "    \n",
    "    # Color gradient: lighter (coarse) to darker (fine) for Jexpresso\n",
    "    jex_colors = {\n",
    "        '4200m': '#FFD9B8',  # Lightest orange\n",
    "        '1200m': '#FFBC85',  # Light orange\n",
    "        '800m': '#FFA55C',   # Medium-light orange\n",
    "        '600m': '#FF8C42',   # Medium orange\n",
    "        '400m': '#D97330',   # Dark orange\n",
    "        '200m': '#A65620'    # Darkest orange\n",
    "    }\n",
    "    \n",
    "    resolutions = ['4200m', '1200m', '800m', '600m', '400m', '200m']\n",
    "    \n",
    "    # Distinct line styles progressing from coarse to fine\n",
    "    linestyles = {\n",
    "        '4200m': (0, (1, 1)),           # Dotted\n",
    "        '1200m': (0, (5, 5)),           # Long dashed\n",
    "        '800m': (0, (5, 2)),            # Dash\n",
    "        '600m': (0, (3, 1, 1, 1)),      # Dash-dot-dot\n",
    "        '400m': (0, (5, 1, 1, 1, 1, 1)),  # Dash-dot-dot with spacing\n",
    "        '200m': '-'                      # Solid (finest resolution)\n",
    "    }\n",
    "    \n",
    "    # Graduated line widths (thicker for finer resolutions)\n",
    "    linewidths = {\n",
    "        '4200m': 1.8,\n",
    "        '1200m': 2.0,\n",
    "        '800m': 2.3,\n",
    "        '600m': 2.6,\n",
    "        '400m': 2.9,\n",
    "        '200m': 3.3\n",
    "    }\n",
    "    \n",
    "    # Distinct markers for each resolution\n",
    "    markers = {\n",
    "        '4200m': 'x',      # Cross\n",
    "        '1200m': 's',      # Square\n",
    "        '800m': 'D',       # Diamond\n",
    "        '600m': 'o',       # Circle\n",
    "        '400m': '^',       # Triangle up\n",
    "        '200m': 'v'        # Triangle down\n",
    "    }\n",
    "    \n",
    "    # Graduated marker sizes (larger for finer resolutions)\n",
    "    markersizes = {\n",
    "        '4200m': 6,\n",
    "        '1200m': 7,\n",
    "        '800m': 8,\n",
    "        '600m': 9,\n",
    "        '400m': 10,\n",
    "        '200m': 11\n",
    "    }\n",
    "    \n",
    "    orders = ['4', '5', '6']\n",
    "    microphysics_types = ['Kessler', 'Cold']\n",
    "    \n",
    "    # First pass: collect all data to determine global y-axis limits\n",
    "    all_values = []\n",
    "    \n",
    "    for order in orders:\n",
    "        for micro in microphysics_types:\n",
    "            for resolution in resolutions:\n",
    "                key = f\"Order_{order}_{resolution}_{micro}\"\n",
    "                if key in data_dict and data_dict[key] is not None:\n",
    "                    data = data_dict[key]\n",
    "                    all_values.extend(data['jex'])\n",
    "    \n",
    "    # Determine global y-axis limits\n",
    "    if len(all_values) > 0:\n",
    "        positive_values = [v for v in all_values if v > 0]\n",
    "        if len(positive_values) > 0:\n",
    "            y_min = max(1e-7, min(positive_values) * 0.3)\n",
    "            y_max = max(positive_values) * 3.0\n",
    "        else:\n",
    "            y_min = 1e-7\n",
    "            y_max = 1e2\n",
    "    else:\n",
    "        y_min = 1e-7\n",
    "        y_max = 1e2\n",
    "    \n",
    "    # Collect legend handles and labels (only once)\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "    legend_collected = False\n",
    "    \n",
    "    # Second pass: create plots with uniform axes\n",
    "    for row_idx, order in enumerate(orders):\n",
    "        for col_idx, micro in enumerate(microphysics_types):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            ax.set_facecolor('#FAFAFA')\n",
    "            \n",
    "            for resolution in resolutions:\n",
    "                key = f\"Order_{order}_{resolution}_{micro}\"\n",
    "                \n",
    "                if key not in data_dict or data_dict[key] is None:\n",
    "                    continue\n",
    "                \n",
    "                data = data_dict[key]\n",
    "                times = data['times']\n",
    "                jex_data = data['jex']\n",
    "                \n",
    "                # Replace zeros and negative values with y_min for log scale\n",
    "                jex_data_plot = [max(v, y_min) for v in jex_data]\n",
    "                \n",
    "                # Plot Jexpresso with color gradient and markers\n",
    "                jex_line = ax.semilogy(times, jex_data_plot, \n",
    "                        color=jex_colors[resolution],\n",
    "                        linestyle=linestyles[resolution],\n",
    "                        marker=markers[resolution],\n",
    "                        markersize=markersizes[resolution],\n",
    "                        linewidth=linewidths[resolution],\n",
    "                        label=f'JEx {resolution}',\n",
    "                        alpha=0.90,\n",
    "                        markevery=max(1, len(times)//10),\n",
    "                        markeredgewidth=1.2,\n",
    "                        markeredgecolor='white',\n",
    "                        zorder=4)\n",
    "                \n",
    "                # Collect legend items from first subplot only\n",
    "                if not legend_collected:\n",
    "                    legend_handles.append(jex_line[0])\n",
    "                    legend_labels.append(f'JEx {resolution}')\n",
    "            \n",
    "            # Mark legend as collected after first subplot\n",
    "            if row_idx == 0 and col_idx == 0:\n",
    "                legend_collected = True\n",
    "            \n",
    "            # Set uniform y-axis limits for all subplots\n",
    "            ax.set_ylim(y_min, y_max)\n",
    "            ax.set_xlim(0, 500)\n",
    "            \n",
    "            if row_idx == 2:\n",
    "                ax.set_xlabel('Time (minutes)', fontsize=13, fontweight='600')\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel('Mean EKE (J/m³)', fontsize=13, fontweight='600')\n",
    "            \n",
    "            title = f'Order {order} - {micro}'\n",
    "            ax.set_title(title, fontsize=14, fontweight='700', pad=12)\n",
    "            \n",
    "            # Enhanced grid\n",
    "            ax.grid(True, alpha=0.15, color='gray', linewidth=0.5, linestyle=':', which='minor')\n",
    "            ax.grid(True, alpha=0.35, color='gray', linewidth=0.8, linestyle='-', which='major')\n",
    "            \n",
    "            # Enhanced spines\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_color('#333333')\n",
    "                spine.set_linewidth(1.3)\n",
    "            \n",
    "            # Improve tick appearance\n",
    "            ax.tick_params(axis='both', which='major', labelsize=10, width=1.2, length=6)\n",
    "            ax.tick_params(axis='both', which='minor', width=0.8, length=3)\n",
    "    \n",
    "    # Create main title\n",
    "    plt.suptitle('JExpresso EKE Analysis: Orders 4, 5, 6\\nAll Resolutions and Microphysics Schemes', \n",
    "                fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Add legend below the plots\n",
    "    fig.legend(legend_handles, legend_labels, \n",
    "              loc='lower center', \n",
    "              bbox_to_anchor=(0.5, -0.02),\n",
    "              ncol=6,\n",
    "              fontsize=10,\n",
    "              frameon=True,\n",
    "              fancybox=True,\n",
    "              framealpha=0.97,\n",
    "              edgecolor='#CCCCCC',\n",
    "              borderpad=0.8)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.99])\n",
    "    \n",
    "    filename = \"JExpresso_Grid_Publication_Quality.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    plt.savefig(filepath, dpi=400, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "    plt.close()\n",
    "    print(f\"Saved publication-quality grid: {filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Create output directory\n",
    "    output_base = \"/Users/olayemiadeyemi/Documents/sponge_on\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"Starting JExpresso EKE Analysis - Publication Quality\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Define all file paths\n",
    "    # JExpresso Reference files for each order\n",
    "    jexpresso_reference = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/coarse_4\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/medium_4\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_800_4/output/iter_0.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_600_4/output/iter_0.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_400_4/output/iter_0.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/fine_4\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/coarse_5\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/medium_5\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_800_5/output/iter_0.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_600_5/output/iter_0.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_400_5/output/iter_0.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/fine_5\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/coarse_6\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/medium_6\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_800_6/output/iter_0.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_600_6/output/iter_0.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_400_6/output/iter_0.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/fine_6\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # JExpresso Kessler paths\n",
    "    jexpresso_kessler = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_k_4/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_k_4/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_800_4_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_600_4_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_400_4_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/f_150_k_4/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_k_5/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_k_5/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_800_5_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_600_5_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_400_5_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_200_5_c5/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_k_6/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_k_6/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_800_6_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_600_6_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_400_6_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_200_6_c5/output/iter_{}.pvtu\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # JExpresso Cold paths\n",
    "    jexpresso_cold = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_sam_4/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_sam_4/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_800_4_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_600_4_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_400_4_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/f_150_sam_4/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_sam_5/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_sam_5/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_800_5_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_600_5_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_400_5_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_200_5_c5/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_sam_6/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_sam_6/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_800_6_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_600_6_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_400_6_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_200_6_c5/output/iter_{}.pvtu\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Process all configurations\n",
    "    all_data = {}\n",
    "    \n",
    "    orders = ['4', '5', '6']\n",
    "    resolutions = ['4200m', '1200m', '800m', '600m', '400m', '200m']\n",
    "    microphysics_types = ['Kessler', 'Cold']\n",
    "    \n",
    "    print(\"\\nProcessing configurations...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for order in orders:\n",
    "        for resolution in resolutions:\n",
    "            for micro in microphysics_types:\n",
    "                print(f\"\\nProcessing: Order {order}, Resolution {resolution}, {micro}\")\n",
    "                \n",
    "                if micro == 'Kessler':\n",
    "                    jex_pert = jexpresso_kessler[order][resolution]\n",
    "                else:\n",
    "                    jex_pert = jexpresso_cold[order][resolution]\n",
    "                \n",
    "                ref_file = jexpresso_reference[order][resolution]\n",
    "                \n",
    "                # Handle directory-based reference files\n",
    "                if not ref_file.endswith('.pvtu'):\n",
    "                    ref_file = os.path.join(ref_file, 'output', 'iter_0.pvtu')\n",
    "                \n",
    "                # Process Jexpresso\n",
    "                try:\n",
    "                    time_data = process_configuration(ref_file, jex_pert, max_time_minutes=500)\n",
    "                    \n",
    "                    if time_data and len(time_data['jex']) > 0:\n",
    "                        key = f\"Order_{order}_{resolution}_{micro}\"\n",
    "                        all_data[key] = time_data\n",
    "                        print(f\"✓ Successfully processed {key} ({len(time_data['jex'])} time steps)\")\n",
    "                    else:\n",
    "                        print(f\"✗ No valid data for Order {order}, {resolution}, {micro}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"✗ Failed to process Order {order}, {resolution}, {micro}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Data processing complete. Successfully processed {len(all_data)} configurations.\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Generate publication-quality comprehensive grid plot\n",
    "    print(\"\\nGenerating publication-quality comprehensive grid plot...\")\n",
    "    print(\"-\" * 80)\n",
    "    plot_comprehensive_grid(all_data, output_base)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Publication-quality plot generated successfully!\")\n",
    "    print(f\"Output directory: {output_base}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"  - Publication-quality grid: {output_base}/JExpresso_Grid_Publication_Quality.png\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa285794-62c4-422a-a675-7de169530d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6caad1-9629-4ab2-9a30-cb28e940096d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c77dd96-bef3-455f-a0b5-36c0ee741bc5",
   "metadata": {},
   "source": [
    "### WRF vs Jexpresso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d57b5-0b14-40d0-a2c9-e8348a4b0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from wrf import getvar, destagger\n",
    "import pyvista as pv\n",
    "from scipy.interpolate import interp1d\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import traceback\n",
    "import os\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='wrf')\n",
    "\n",
    "\n",
    "class EKEComparison:\n",
    "    \"\"\"Compare WRF and JExpresso outputs using Domain Mean Subtraction method\"\"\"\n",
    "    \n",
    "    def __init__(self, wrf_file, ref_file, pert_file, max_height=24000):\n",
    "        self.wrf_file = wrf_file\n",
    "        self.ref_file = ref_file\n",
    "        self.pert_file = pert_file\n",
    "        self.max_height = max_height\n",
    "        self.R_d = 287.05\n",
    "\n",
    "    def extract_wrf_data(self, timeidx=0):\n",
    "        with Dataset(self.wrf_file) as ncfile:\n",
    "            z = getvar(ncfile, \"z\", timeidx=timeidx, meta=False)\n",
    "            u_full = destagger(getvar(ncfile, \"ua\", timeidx=timeidx, meta=False), -1)\n",
    "            v_full = destagger(getvar(ncfile, \"va\", timeidx=timeidx, meta=False), -1)\n",
    "            z = z[:, :, :-1]\n",
    "            t = getvar(ncfile, \"tk\", timeidx=timeidx, meta=False)[:, :, :-1]\n",
    "            qv = getvar(ncfile, \"QVAPOR\", timeidx=timeidx, meta=False)[:, :, :-1]\n",
    "            p = getvar(ncfile, \"P\", timeidx=timeidx, meta=False)[:, :, :-1]\n",
    "            pb = getvar(ncfile, \"PB\", timeidx=timeidx, meta=False)[:, :, :-1]\n",
    "            \n",
    "            Tv_full = t * (1 + 0.61 * qv)\n",
    "            pressure_full = p + pb\n",
    "            rho_full = pressure_full / (self.R_d * Tv_full)\n",
    "            \n",
    "            nz, ny, nx = u_full.shape\n",
    "            eke_profile = []\n",
    "            height_profile = []\n",
    "            \n",
    "            for k in range(nz):\n",
    "                u_level = u_full[k, :, :]\n",
    "                v_level = v_full[k, :, :]\n",
    "                rho_level = rho_full[k, :, :]\n",
    "                z_level = z[k, :, :]\n",
    "                \n",
    "                mean_height = np.mean(z_level)\n",
    "                height_profile.append(mean_height)\n",
    "                \n",
    "                u_horizontal_mean = np.mean(u_level)\n",
    "                v_horizontal_mean = np.mean(v_level)\n",
    "                u_pert = u_level - u_horizontal_mean\n",
    "                v_pert = v_level - v_horizontal_mean\n",
    "                eke = 0.5 * rho_level * (u_pert**2 + v_pert**2)\n",
    "                eke_profile.append(np.mean(eke))\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"Height (m)\": height_profile,\n",
    "            \"EKE (J/m3)\": eke_profile\n",
    "        })\n",
    "        self.wrf_data = df[df[\"Height (m)\"] <= self.max_height].reset_index(drop=True)\n",
    "\n",
    "    def extract_jexpresso_data(self):\n",
    "        ref_mesh = pv.read(self.ref_file)\n",
    "        pert_mesh = pv.read(self.pert_file)\n",
    "        \n",
    "        if ref_mesh.n_points != pert_mesh.n_points:\n",
    "            z_ref = ref_mesh.points[:, 1]\n",
    "            ref_sort_idx = np.argsort(z_ref)\n",
    "            z_ref_sorted = z_ref[ref_sort_idx]\n",
    "            rho_ref = ref_mesh.point_data['ρ'][ref_sort_idx]\n",
    "            rho_u_ref = ref_mesh.point_data['ρu'][ref_sort_idx]\n",
    "            rho_v_ref = ref_mesh.point_data['ρv'][ref_sort_idx]\n",
    "            \n",
    "            z_pert = pert_mesh.points[:, 1]\n",
    "            pert_sort_idx = np.argsort(z_pert)\n",
    "            z_pert_sorted = z_pert[pert_sort_idx]\n",
    "            rho_pert = pert_mesh.point_data['ρ'][pert_sort_idx]\n",
    "            rho_u_pert = pert_mesh.point_data['ρu'][pert_sort_idx]\n",
    "            rho_v_pert = pert_mesh.point_data['ρv'][pert_sort_idx]\n",
    "            \n",
    "            if len(z_ref_sorted) > len(z_pert_sorted):\n",
    "                z_common = z_ref_sorted\n",
    "                f_rho_pert = interp1d(z_pert_sorted, rho_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_u_pert = interp1d(z_pert_sorted, rho_u_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_v_pert = interp1d(z_pert_sorted, rho_v_pert, bounds_error=False, fill_value=0, kind='linear')\n",
    "                \n",
    "                rho_total = rho_ref + f_rho_pert(z_common)\n",
    "                rho_u_total = rho_u_ref + f_rho_u_pert(z_common)\n",
    "                rho_v_total = rho_v_ref + f_rho_v_pert(z_common)\n",
    "            else:\n",
    "                z_common = z_pert_sorted\n",
    "                f_rho_ref = interp1d(z_ref_sorted, rho_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_u_ref = interp1d(z_ref_sorted, rho_u_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                f_rho_v_ref = interp1d(z_ref_sorted, rho_v_ref, bounds_error=False, fill_value=0, kind='linear')\n",
    "                \n",
    "                rho_total = f_rho_ref(z_common) + rho_pert\n",
    "                rho_u_total = f_rho_u_ref(z_common) + rho_u_pert\n",
    "                rho_v_total = f_rho_v_ref(z_common) + rho_v_pert\n",
    "        else:\n",
    "            z_common = ref_mesh.points[:, 1]\n",
    "            rho_total = ref_mesh.point_data['ρ'] + pert_mesh.point_data['ρ']\n",
    "            rho_u_total = ref_mesh.point_data['ρu'] + pert_mesh.point_data['ρu']\n",
    "            rho_v_total = ref_mesh.point_data['ρv'] + pert_mesh.point_data['ρv']\n",
    "        \n",
    "        valid_mask = np.abs(rho_total) > 1e-10\n",
    "        u_total = np.zeros_like(rho_u_total)\n",
    "        v_total = np.zeros_like(rho_v_total)\n",
    "        u_total[valid_mask] = rho_u_total[valid_mask] / rho_total[valid_mask]\n",
    "        v_total[valid_mask] = rho_v_total[valid_mask] / rho_total[valid_mask]\n",
    "        \n",
    "        height_tolerance = 100.0\n",
    "        heights_rounded = np.round(z_common / height_tolerance) * height_tolerance\n",
    "        unique_heights_rounded = np.unique(heights_rounded)\n",
    "        \n",
    "        eke_profile = []\n",
    "        height_profile = []\n",
    "        \n",
    "        for h_target in unique_heights_rounded:\n",
    "            height_mask = np.abs(heights_rounded - h_target) < (height_tolerance / 2)\n",
    "            if np.sum(height_mask) < 2:\n",
    "                continue\n",
    "                \n",
    "            u_total_level = u_total[height_mask]\n",
    "            v_total_level = v_total[height_mask]\n",
    "            rho_level = rho_total[height_mask]\n",
    "            z_level = z_common[height_mask]\n",
    "            \n",
    "            valid_level_mask = (rho_level > 1e-10) & np.isfinite(u_total_level) & np.isfinite(v_total_level)\n",
    "            if np.sum(valid_level_mask) < 2:\n",
    "                continue\n",
    "                \n",
    "            u_total_level = u_total_level[valid_level_mask]\n",
    "            v_total_level = v_total_level[valid_level_mask]\n",
    "            rho_level = rho_level[valid_level_mask]\n",
    "            z_level = z_level[valid_level_mask]\n",
    "            \n",
    "            u_mean_level = np.mean(u_total_level)\n",
    "            v_mean_level = np.mean(v_total_level)\n",
    "            u_pert = u_total_level - u_mean_level\n",
    "            v_pert = v_total_level - v_mean_level\n",
    "            eke = 0.5 * rho_level * (u_pert**2 + v_pert**2)\n",
    "            eke_mean = np.mean(eke)\n",
    "            \n",
    "            if eke_mean > 1000 or eke_mean < 0 or not np.isfinite(eke_mean):\n",
    "                continue\n",
    "                \n",
    "            eke_profile.append(eke_mean)\n",
    "            height_profile.append(np.mean(z_level))\n",
    "            \n",
    "        if len(eke_profile) == 0:\n",
    "            self.jex_data = pd.DataFrame({'Height (m)': [], 'EKE (J/m3)': []})\n",
    "            return\n",
    "        \n",
    "        df_raw = pd.DataFrame({\n",
    "            \"Height (m)\": height_profile,\n",
    "            \"EKE (J/m3)\": eke_profile\n",
    "        })\n",
    "        self.jex_data = df_raw[df_raw[\"Height (m)\"] <= self.max_height].drop_duplicates(subset=[\"Height (m)\"]).sort_values('Height (m)').reset_index(drop=True)\n",
    "\n",
    "    def interpolate_to_wrf_heights(self):\n",
    "        df_jex = self.jex_data\n",
    "        if len(df_jex) == 0:\n",
    "            heights_wrf = self.wrf_data[\"Height (m)\"].values\n",
    "            return np.full_like(heights_wrf, np.nan)\n",
    "            \n",
    "        heights_wrf = self.wrf_data[\"Height (m)\"].values\n",
    "        valid_mask = ~np.isnan(df_jex[\"EKE (J/m3)\"])\n",
    "        \n",
    "        if valid_mask.sum() < 2:\n",
    "            return np.full_like(heights_wrf, np.nan)\n",
    "        \n",
    "        try:\n",
    "            f = interp1d(\n",
    "                df_jex[\"Height (m)\"][valid_mask], \n",
    "                df_jex[\"EKE (J/m3)\"][valid_mask], \n",
    "                bounds_error=False, \n",
    "                fill_value=\"extrapolate\",\n",
    "                kind='linear'\n",
    "            )\n",
    "            return f(heights_wrf)\n",
    "        except Exception as e:\n",
    "            return np.full_like(heights_wrf, np.nan)\n",
    "\n",
    "    def get_comparison_data(self):\n",
    "        jex_eke_interp = self.interpolate_to_wrf_heights()\n",
    "        return {\n",
    "            \"heights\": self.wrf_data[\"Height (m)\"].values,\n",
    "            \"wrf_eke\": self.wrf_data[\"EKE (J/m3)\"].values,\n",
    "            \"jex_eke\": jex_eke_interp\n",
    "        }\n",
    "\n",
    "\n",
    "def process_configuration(wrf_file, ref_file, pert_base_path, max_time_minutes=500):\n",
    "    \"\"\"Process configuration and stop at max_time_minutes (default 500)\"\"\"\n",
    "    \n",
    "    if not Path(wrf_file).exists():\n",
    "        print(f\"WRF file not found: {wrf_file}\")\n",
    "        return None\n",
    "    \n",
    "    if not Path(ref_file).exists():\n",
    "        print(f\"Reference file not found: {ref_file}\")\n",
    "        return None\n",
    "    \n",
    "    time_data = {'wrf': [], 'jex': [], 'times': []}\n",
    "    \n",
    "    max_iterations = max_time_minutes // 10\n",
    "    existing_pert_files = [i for i in range(max_iterations) if Path(pert_base_path.format(i)).exists()]\n",
    "    \n",
    "    if not existing_pert_files:\n",
    "        print(f\"No perturbation files found at: {pert_base_path}\")\n",
    "        return None\n",
    "    \n",
    "    successful_iterations = 0\n",
    "    for i in existing_pert_files:\n",
    "        try:\n",
    "            comparison = EKEComparison(wrf_file, ref_file, pert_base_path.format(i), max_height=24000)\n",
    "            comparison.extract_wrf_data(timeidx=i)\n",
    "            comparison.extract_jexpresso_data()\n",
    "            comp_data = comparison.get_comparison_data()\n",
    "            \n",
    "            if len(comp_data['wrf_eke']) == 0 or np.all(np.isnan(comp_data['wrf_eke'])) or np.all(np.isnan(comp_data['jex_eke'])):\n",
    "                continue\n",
    "            \n",
    "            wrf_total_eke = np.nanmean(comp_data['wrf_eke'])\n",
    "            jex_total_eke = np.nanmean(comp_data['jex_eke'])\n",
    "            \n",
    "            if wrf_total_eke > 500 or jex_total_eke > 500:\n",
    "                continue\n",
    "            \n",
    "            time_data['wrf'].append(wrf_total_eke)\n",
    "            time_data['jex'].append(jex_total_eke)\n",
    "            time_data['times'].append(i * 10)\n",
    "            successful_iterations += 1\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    print(f\"Successfully processed {successful_iterations} time steps\")\n",
    "    return time_data if len(time_data['wrf']) > 0 else None\n",
    "\n",
    "\n",
    "def plot_comprehensive_grid(data_dict, output_dir):\n",
    "    \"\"\"Create publication-quality comprehensive 3x2 grid with color gradients and distinct styling\"\"\"\n",
    "    \n",
    "    # Set publication-quality matplotlib parameters\n",
    "    plt.rcParams['font.family'] = 'sans-serif'\n",
    "    plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    plt.rcParams['axes.linewidth'] = 1.2\n",
    "    plt.rcParams['xtick.major.width'] = 1.2\n",
    "    plt.rcParams['ytick.major.width'] = 1.2\n",
    "    \n",
    "    # Adjusted figure size to accommodate legend below\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(20, 17))\n",
    "    \n",
    "    # Color gradients: lighter (coarse) to darker (fine) for both WRF and Jexpresso\n",
    "    wrf_colors = {\n",
    "        '4200m': '#A8C5E8',  # Lightest blue\n",
    "        '1200m': '#7AAAD9',  # Light blue\n",
    "        '800m': '#5290CA',   # Medium-light blue\n",
    "        '600m': '#2E5CB8',   # Medium blue (original)\n",
    "        '400m': '#1E4A9A',   # Dark blue\n",
    "        '200m': '#0F2F5C'    # Darkest blue\n",
    "    }\n",
    "    \n",
    "    jex_colors = {\n",
    "        '4200m': '#FFD9B8',  # Lightest orange\n",
    "        '1200m': '#FFBC85',  # Light orange\n",
    "        '800m': '#FFA55C',   # Medium-light orange\n",
    "        '600m': '#FF8C42',   # Medium orange (original)\n",
    "        '400m': '#D97330',   # Dark orange\n",
    "        '200m': '#A65620'    # Darkest orange\n",
    "    }\n",
    "    \n",
    "    resolutions = ['4200m', '1200m', '800m', '600m', '400m', '200m']\n",
    "    \n",
    "    # Distinct line styles progressing from coarse to fine\n",
    "    linestyles = {\n",
    "        '4200m': (0, (1, 1)),           # Dotted\n",
    "        '1200m': (0, (5, 5)),           # Long dashed\n",
    "        '800m': (0, (5, 2)),            # Dash\n",
    "        '600m': (0, (3, 1, 1, 1)),      # Dash-dot-dot\n",
    "        '400m': (0, (5, 1, 1, 1, 1, 1)),  # Dash-dot-dot with spacing\n",
    "        '200m': '-'                      # Solid (finest resolution)\n",
    "    }\n",
    "    \n",
    "    # Graduated line widths (thicker for finer resolutions)\n",
    "    linewidths = {\n",
    "        '4200m': 1.8,\n",
    "        '1200m': 2.0,\n",
    "        '800m': 2.3,\n",
    "        '600m': 2.6,\n",
    "        '400m': 2.9,\n",
    "        '200m': 3.3\n",
    "    }\n",
    "    \n",
    "    # Distinct markers for each resolution\n",
    "    markers = {\n",
    "        '4200m': 'x',      # Cross\n",
    "        '1200m': 's',      # Square\n",
    "        '800m': 'D',       # Diamond\n",
    "        '600m': 'o',       # Circle\n",
    "        '400m': '^',       # Triangle up\n",
    "        '200m': 'v'        # Triangle down\n",
    "    }\n",
    "    \n",
    "    # Graduated marker sizes (larger for finer resolutions)\n",
    "    markersizes = {\n",
    "        '4200m': 6,\n",
    "        '1200m': 7,\n",
    "        '800m': 8,\n",
    "        '600m': 9,\n",
    "        '400m': 10,\n",
    "        '200m': 11\n",
    "    }\n",
    "    \n",
    "    orders = ['4', '5', '6']\n",
    "    microphysics_types = ['Kessler', 'Cold']\n",
    "    \n",
    "    # First pass: collect all data to determine global y-axis limits\n",
    "    all_wrf_values = []\n",
    "    all_jex_values = []\n",
    "    \n",
    "    for order in orders:\n",
    "        for micro in microphysics_types:\n",
    "            for resolution in resolutions:\n",
    "                key = f\"Order_{order}_{resolution}_{micro}\"\n",
    "                if key in data_dict and data_dict[key] is not None:\n",
    "                    data = data_dict[key]\n",
    "                    all_wrf_values.extend(data['wrf'])\n",
    "                    all_jex_values.extend(data['jex'])\n",
    "    \n",
    "    # Determine global y-axis limits\n",
    "    all_values = all_wrf_values + all_jex_values\n",
    "    if len(all_values) > 0:\n",
    "        positive_values = [v for v in all_values if v > 0]\n",
    "        if len(positive_values) > 0:\n",
    "            y_min = max(1e-7, min(positive_values) * 0.3)\n",
    "            y_max = max(positive_values) * 3.0\n",
    "        else:\n",
    "            y_min = 1e-7\n",
    "            y_max = 1e2\n",
    "    else:\n",
    "        y_min = 1e-7\n",
    "        y_max = 1e2\n",
    "    \n",
    "    # Collect legend handles and labels (only once)\n",
    "    legend_handles = []\n",
    "    legend_labels = []\n",
    "    legend_collected = False\n",
    "    \n",
    "    # Second pass: create plots with uniform axes\n",
    "    for row_idx, order in enumerate(orders):\n",
    "        for col_idx, micro in enumerate(microphysics_types):\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            ax.set_facecolor('#FAFAFA')\n",
    "            \n",
    "            # Track which resolutions have been plotted for this subplot\n",
    "            wrf_plotted = set()\n",
    "            \n",
    "            for resolution in resolutions:\n",
    "                key = f\"Order_{order}_{resolution}_{micro}\"\n",
    "                \n",
    "                if key not in data_dict or data_dict[key] is None:\n",
    "                    continue\n",
    "                \n",
    "                data = data_dict[key]\n",
    "                times = data['times']\n",
    "                wrf_data = data['wrf']\n",
    "                jex_data = data['jex']\n",
    "                \n",
    "                # Replace zeros and negative values with y_min for log scale\n",
    "                wrf_data_plot = [max(v, y_min) for v in wrf_data]\n",
    "                jex_data_plot = [max(v, y_min) for v in jex_data]\n",
    "                \n",
    "                # Plot WRF for all subplots (WRF is the same baseline for all orders)\n",
    "                if resolution not in wrf_plotted:\n",
    "                    wrf_line = ax.semilogy(times, wrf_data_plot, \n",
    "                            color=wrf_colors[resolution],\n",
    "                            linestyle=linestyles[resolution],\n",
    "                            linewidth=linewidths[resolution],\n",
    "                            label=f'WRF {resolution}',\n",
    "                            alpha=0.95,\n",
    "                            zorder=5)\n",
    "                    wrf_plotted.add(resolution)\n",
    "                    \n",
    "                    # Collect legend items from first subplot only\n",
    "                    if not legend_collected:\n",
    "                        legend_handles.append(wrf_line[0])\n",
    "                        legend_labels.append(f'WRF {resolution}')\n",
    "                \n",
    "                # Plot Jexpresso with color gradient and markers\n",
    "                jex_line = ax.semilogy(times, jex_data_plot, \n",
    "                        color=jex_colors[resolution],\n",
    "                        linestyle=linestyles[resolution],\n",
    "                        marker=markers[resolution],\n",
    "                        markersize=markersizes[resolution],\n",
    "                        linewidth=linewidths[resolution],\n",
    "                        label=f'JEx {resolution}',\n",
    "                        alpha=0.90,\n",
    "                        markevery=max(1, len(times)//10),\n",
    "                        markeredgewidth=1.2,\n",
    "                        markeredgecolor='white',\n",
    "                        zorder=4)\n",
    "                \n",
    "                # Collect legend items from first subplot only\n",
    "                if not legend_collected:\n",
    "                    legend_handles.append(jex_line[0])\n",
    "                    legend_labels.append(f'JEx {resolution}')\n",
    "            \n",
    "            # Mark legend as collected after first subplot\n",
    "            if row_idx == 0 and col_idx == 0:\n",
    "                legend_collected = True\n",
    "            \n",
    "            # Set uniform y-axis limits for all subplots\n",
    "            ax.set_ylim(y_min, y_max)\n",
    "            ax.set_xlim(0, 500)\n",
    "            \n",
    "            if row_idx == 2:\n",
    "                ax.set_xlabel('Time (minutes)', fontsize=13, fontweight='600')\n",
    "            if col_idx == 0:\n",
    "                ax.set_ylabel('Mean EKE (J/m³)', fontsize=13, fontweight='600')\n",
    "            \n",
    "            title = f'Order {order} - {micro}'\n",
    "            ax.set_title(title, fontsize=14, fontweight='700', pad=12)\n",
    "            \n",
    "            # Enhanced grid\n",
    "            ax.grid(True, alpha=0.15, color='gray', linewidth=0.5, linestyle=':', which='minor')\n",
    "            ax.grid(True, alpha=0.35, color='gray', linewidth=0.8, linestyle='-', which='major')\n",
    "            \n",
    "            # Enhanced spines\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_color('#333333')\n",
    "                spine.set_linewidth(1.3)\n",
    "            \n",
    "            # Improve tick appearance\n",
    "            ax.tick_params(axis='both', which='major', labelsize=10, width=1.2, length=6)\n",
    "            ax.tick_params(axis='both', which='minor', width=0.8, length=3)\n",
    "    \n",
    "    # Create main title\n",
    "    plt.suptitle('Comprehensive EKE Comparison: WRF vs Jexpresso (Orders 4, 5, 6)\\nAll Resolutions and Microphysics Schemes', \n",
    "                fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Add legend below the plots\n",
    "    fig.legend(legend_handles, legend_labels, \n",
    "              loc='lower center', \n",
    "              bbox_to_anchor=(0.5, -0.02),\n",
    "              ncol=6,\n",
    "              fontsize=10,\n",
    "              frameon=True,\n",
    "              fancybox=True,\n",
    "              framealpha=0.97,\n",
    "              edgecolor='#CCCCCC',\n",
    "              borderpad=0.8)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.99])\n",
    "    \n",
    "    filename = \"Comprehensive_Grid_Publication_Quality.png\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    plt.savefig(filepath, dpi=400, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "    plt.close()\n",
    "    print(f\"Saved publication-quality grid: {filename}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Create output directory structure - only main directory needed\n",
    "    output_base = \"/Users/olayemiadeyemi/Documents/sponge_on\"\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"Starting EKE Comprehensive Analysis - Publication Quality\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Define all file paths\n",
    "    # JExpresso Reference files for each order\n",
    "    jexpresso_reference = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/coarse_4\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/medium_4\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_800_4/output/iter_0.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_600_4/output/iter_0.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_400_4/output/iter_0.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/fine_4\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/coarse_5\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/medium_5\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_800_5/output/iter_0.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_600_5/output/iter_0.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_400_5/output/iter_0.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/fine_5\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/coarse_6\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/medium_6\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_800_6/output/iter_0.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_600_6/output/iter_0.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/ref_400_6/output/iter_0.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/New/reference_state/fine_6\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # JExpresso Kessler paths\n",
    "    jexpresso_kessler = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_k_4/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_k_4/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_800_4_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_600_4_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_400_4_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/f_150_k_4/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_k_5/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_k_5/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_800_5_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_600_5_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_400_5_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_200_5_c5/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_k_6/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_k_6/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_800_6_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_600_6_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_400_6_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_K_200_6_c5/output/iter_{}.pvtu\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # JExpresso Cold paths\n",
    "    jexpresso_cold = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_sam_4/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_sam_4/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_800_4_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_600_4_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_400_4_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/f_150_sam_4/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_sam_5/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_sam_5/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_800_5_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_600_5_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_400_5_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_200_5_c5/output/iter_{}.pvtu\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/c_150_sam_6/output/iter_{}.pvtu\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/m_150_sam_6/output/iter_{}.pvtu\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_800_6_c5/output/iter_{}.pvtu\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_600_6_c5/output/iter_{}.pvtu\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_400_6_c5/output/iter_{}.pvtu\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/fine_S_200_6_c5/output/iter_{}.pvtu\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # WRF Kessler paths\n",
    "    wrf_kessler = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6104-01-01_00_00_00\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6105-01-01_00_00_00\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6020-01-01_00_00_00\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6022-01-01_00_00_00\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6024-01-01_00_00_00\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6106-01-01_00_00_00\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6104-01-01_00_00_00\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6105-01-01_00_00_00\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6020-01-01_00_00_00\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6022-01-01_00_00_00\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6024-01-01_00_00_00\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6106-01-01_00_00_00\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6104-01-01_00_00_00\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6105-01-01_00_00_00\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6020-01-01_00_00_00\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6022-01-01_00_00_00\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6024-01-01_00_00_00\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6106-01-01_00_00_00\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # WRF Cold paths\n",
    "    wrf_cold = {\n",
    "        '4': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6107-01-01_00_00_00\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6108-01-01_00_00_00\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6021-01-01_00_00_00\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6023-01-01_00_00_00\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6025-01-01_00_00_00\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6109-01-01_00_00_00\"\n",
    "        },\n",
    "        '5': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6107-01-01_00_00_00\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6108-01-01_00_00_00\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6021-01-01_00_00_00\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6023-01-01_00_00_00\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6025-01-01_00_00_00\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6109-01-01_00_00_00\"\n",
    "        },\n",
    "        '6': {\n",
    "            '4200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6107-01-01_00_00_00\",\n",
    "            '1200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6108-01-01_00_00_00\",\n",
    "            '800m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6021-01-01_00_00_00\",\n",
    "            '600m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6023-01-01_00_00_00\",\n",
    "            '400m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6025-01-01_00_00_00\",\n",
    "            '200m': \"/Users/olayemiadeyemi/Documents/sponge_on/wrfout_d01_6109-01-01_00_00_00\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Process all configurations\n",
    "    all_data = {}\n",
    "    wrf_cache = {}  # Cache WRF data to avoid redundant processing\n",
    "    \n",
    "    orders = ['4', '5', '6']\n",
    "    resolutions = ['4200m', '1200m', '800m', '600m', '400m', '200m']\n",
    "    microphysics_types = ['Kessler', 'Cold']\n",
    "    \n",
    "    print(\"\\nProcessing configurations...\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for resolution in resolutions:\n",
    "        for micro in microphysics_types:\n",
    "            # Process WRF once per resolution/microphysics combination\n",
    "            wrf_cache_key = f\"{resolution}_{micro}\"\n",
    "            \n",
    "            if micro == 'Kessler':\n",
    "                wrf_file = wrf_kessler['4'][resolution]  # Use order 4 as reference\n",
    "            else:\n",
    "                wrf_file = wrf_cold['4'][resolution]  # Use order 4 as reference\n",
    "            \n",
    "            # Process WRF data once and cache it\n",
    "            if Path(wrf_file).exists():\n",
    "                print(f\"\\nProcessing WRF data for {resolution} {micro}...\")\n",
    "                try:\n",
    "                    # Create a dummy comparison object to extract WRF data\n",
    "                    ref_file_dummy = jexpresso_reference['4'][resolution]\n",
    "                    if not ref_file_dummy.endswith('.pvtu'):\n",
    "                        ref_file_dummy = os.path.join(ref_file_dummy, 'output', 'iter_0.pvtu')\n",
    "                    \n",
    "                    comparison_wrf = EKEComparison(wrf_file, ref_file_dummy, \"\", max_height=24000)\n",
    "                    \n",
    "                    # Extract WRF time series\n",
    "                    wrf_time_data = []\n",
    "                    wrf_times = []\n",
    "                    max_iterations = 50\n",
    "                    \n",
    "                    for i in range(max_iterations):\n",
    "                        try:\n",
    "                            comparison_wrf.extract_wrf_data(timeidx=i)\n",
    "                            wrf_eke = np.nanmean(comparison_wrf.wrf_data[\"EKE (J/m3)\"].values)\n",
    "                            if wrf_eke <= 500 and not np.isnan(wrf_eke):\n",
    "                                wrf_time_data.append(wrf_eke)\n",
    "                                wrf_times.append(i * 10)\n",
    "                        except:\n",
    "                            break\n",
    "                    \n",
    "                    if len(wrf_time_data) > 0:\n",
    "                        wrf_cache[wrf_cache_key] = {\n",
    "                            'wrf_dataframe': comparison_wrf.wrf_data,\n",
    "                            'wrf_time_series': wrf_time_data,\n",
    "                            'times': wrf_times\n",
    "                        }\n",
    "                        print(f\"✓ Cached WRF data for {resolution} {micro} ({len(wrf_time_data)} time steps)\")\n",
    "                    else:\n",
    "                        print(f\"✗ No valid WRF data for {resolution} {micro}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"✗ Failed to process WRF for {resolution} {micro}: {e}\")\n",
    "            \n",
    "            # Now process Jexpresso for each order\n",
    "            for order in orders:\n",
    "                print(f\"\\nProcessing Jexpresso: Order {order}, Resolution {resolution}, {micro}\")\n",
    "                \n",
    "                if micro == 'Kessler':\n",
    "                    jex_pert = jexpresso_kessler[order][resolution]\n",
    "                else:\n",
    "                    jex_pert = jexpresso_cold[order][resolution]\n",
    "                \n",
    "                ref_file = jexpresso_reference[order][resolution]\n",
    "                \n",
    "                # Handle directory-based reference files\n",
    "                if not ref_file.endswith('.pvtu'):\n",
    "                    ref_file = os.path.join(ref_file, 'output', 'iter_0.pvtu')\n",
    "                \n",
    "                # Check if we have cached WRF data\n",
    "                if wrf_cache_key not in wrf_cache:\n",
    "                    print(f\"✗ No WRF cache available for {resolution} {micro}\")\n",
    "                    continue\n",
    "                \n",
    "                # Process Jexpresso\n",
    "                try:\n",
    "                    time_data = {'wrf': wrf_cache[wrf_cache_key]['wrf_time_series'].copy(),\n",
    "                               'jex': [],\n",
    "                               'times': wrf_cache[wrf_cache_key]['times'].copy()}\n",
    "                    \n",
    "                    max_iterations = 50\n",
    "                    existing_pert_files = [i for i in range(max_iterations) if Path(jex_pert.format(i)).exists()]\n",
    "                    \n",
    "                    if not existing_pert_files:\n",
    "                        print(f\"✗ No perturbation files found\")\n",
    "                        continue\n",
    "                    \n",
    "                    for i in existing_pert_files:\n",
    "                        if i * 10 not in time_data['times']:\n",
    "                            continue\n",
    "                        try:\n",
    "                            comparison_jex = EKEComparison(wrf_file, ref_file, jex_pert.format(i), max_height=24000)\n",
    "                            comparison_jex.wrf_data = wrf_cache[wrf_cache_key]['wrf_dataframe']\n",
    "                            comparison_jex.extract_jexpresso_data()\n",
    "                            comp_data = comparison_jex.get_comparison_data()\n",
    "                            \n",
    "                            if len(comp_data['jex_eke']) == 0 or np.all(np.isnan(comp_data['jex_eke'])):\n",
    "                                continue\n",
    "                            \n",
    "                            jex_total_eke = np.nanmean(comp_data['jex_eke'])\n",
    "                            \n",
    "                            if jex_total_eke > 500 or jex_total_eke < 0 or not np.isfinite(jex_total_eke):\n",
    "                                continue\n",
    "                            \n",
    "                            time_data['jex'].append(jex_total_eke)\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    # Trim to match lengths\n",
    "                    min_len = min(len(time_data['wrf']), len(time_data['jex']))\n",
    "                    time_data['wrf'] = time_data['wrf'][:min_len]\n",
    "                    time_data['jex'] = time_data['jex'][:min_len]\n",
    "                    time_data['times'] = time_data['times'][:min_len]\n",
    "                    \n",
    "                    if len(time_data['jex']) > 0:\n",
    "                        key = f\"Order_{order}_{resolution}_{micro}\"\n",
    "                        all_data[key] = time_data\n",
    "                        print(f\"✓ Successfully processed {key} ({len(time_data['jex'])} time steps)\")\n",
    "                    else:\n",
    "                        print(f\"✗ No valid Jexpresso data for Order {order}, {resolution}, {micro}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"✗ Failed to process Order {order}, {resolution}, {micro}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Data processing complete. Successfully processed {len(all_data)} configurations.\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Generate publication-quality comprehensive grid plot\n",
    "    print(\"\\nGenerating publication-quality comprehensive grid plot...\")\n",
    "    print(\"-\" * 80)\n",
    "    plot_comprehensive_grid(all_data, output_base)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Publication-quality plot generated successfully!\")\n",
    "    print(f\"Output directory: {output_base}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"  - Publication-quality grid: {output_base}/Comprehensive_Grid_Publication_Quality.png\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f4f67-eb0d-41bf-97c5-af0beac4b6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6527d36b-b333-437a-b333-5186e09b220e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf44a2-9006-419f-b8db-3d4b80b62703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8983d-3a8e-47b6-9ddc-3c931ee85639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
